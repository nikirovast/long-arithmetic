% Diese Zeile bitte -nicht- aendern.
\documentclass[course=erap]{aspdoc}
\usepackage{mathtools}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% TODO: Ersetzen Sie in den folgenden Zeilen die entsprechenden -Texte-
%% mit den richtigen Werten.
\newcommand{\theGroup}{147} % Beispiel: 42
\newcommand{\theNumber}{A326} % Beispiel: A123
\author{Yulia Nikirova \and Andriy Manucharyan}
\date{Sommersemester 2021} % Beispiel: Wintersemester 2019/20
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Diese Zeile bitte -nicht- aendern.
\title{Gruppe \theGroup{} -- Abgabe zu Aufgabe \theNumber}

\begin{document}
\maketitle

\section{Einleitung}
Die vorliegende Arbeit beschäftigt sich mit dem Algorithmus der schnellen Exponentiation von Matrizen von großen Zahlen und seiner Anwendung auf die iterative Berechnung der Konstante  \(\sqrt{2}\) mit der beliebigen vom Benutzer wählbaren Genauigkeit. Zu diesem Zweck wurde eine Methode zur Speicherung langer Zahlen und zur effizienten Durchführung mathematischer Operationen auf diesen entwickelt und die Anzahl der Operationen, die zum Erreichen einer bestimmten Genauigkeit erforderlich sind, mathematisch abgeschätzt.
\section{Lösungsansatz}
\subsection{Überblick}%
Die iterative Formel, die wir zur Berechnung der Konstante \(\sqrt{2}\) verwenden, lautet wie folgt:
\begin{equation}\label{eq:iterativeSqrt2}
\lim_{n \to \infty} {1+\frac{x_n}{x_{n+1}}} = \sqrt{2} 
\end{equation}
Wobei die $x_n$ und $x_{n+1}$ Terme sich durch die Exponentiation der Matrix
$\begin{pmatrix}
  0 & 1\\ 
  1 & 2
\end{pmatrix}$ bestimmen lassen, das heißt:
\begin{equation}\label{eq:matrixPower}
{\begin{pmatrix}
x_{n-1} & x_n \\
x_n & x_{n+1}
\end{pmatrix} } =
{\begin{pmatrix}
0 & 1\\
1 & 2
\end{pmatrix} }^n
\end{equation}
Um (\ref{eq:matrixPower}) zu berechnen, verwenden wir die schnelle Exponentiation, die im Folgenden im Detail erläutert wird.
\subsection{Korrektheit der schnellen Exponentiation}%
Schnelle Exponentiation erlaubt es, wie der Name schon sagt, eine Zahl schneller zu potenzieren als die naive Exponentiation: \begin{equation}
x^n = \underbrace{x \cdot x \cdot x \cdot ... \cdot x}_\text{n mal}
\end{equation} 
Um das Verfahren besser zu schildern, beschreiben wir das Prinzip anhand eines Beispiels: $n = 37$. Diese Zahl lässt sich als Summe von den Zweierpotenzen darstellen:
\begin{equation}
 37 = 1 \cdot 2^0 + 0 \cdot 2^1 + 1 \cdot 2^2 + 0 \cdot 2^3 + 0 \cdot 2^4 + 1 \cdot 2^5 = 1 + 4 + 32
\end{equation}
Offensichtlich gilt unter anderem: 
\begin{equation}
    x^{37} = x^{32} \cdot x^4 \cdot x^1
\end{equation}
Daraus ergibt sich, dass die bisher enstandene Zahl mit sich selbst $k$ mal multipliziert wird, wobei $k$ das höchstgesetzte Bit der binären Darstellung von $n$ ist, und falls an der $i$-ten Stelle eine $1$ steht, wird $x^i$ mit dem bisher erreichten Ergebnis multiplziert, ansonsten weiter potenziert bis das letzte Bit abgearbeitet wurde. Am Ende ergibt sich genau das gleiche Ergebnis wie bei der normalen Exponentiation. In unserer Implementierung haben wir dieses Verfahren angepasst, was in folgendem Abschnitt verdeutlicht wird. 
\subsection{Übertragung der schnellen Exponentiation auf Matrizen}%
Bevor wir uns in die Implementierung vertiefen, wollen wir anmerken, dass laut der Aufgabenstellung müssen wir lediglich die Exponentiation auf die 2x2 Blockmatrizen übertragen. Außerdem sind in allen Matrizen, die im Laufe der Exponetiation entstehen, nur $3$ unterschiedliche Werte vorhanden, weil $x^n$ immer $2$ mal vorkommt. Dies vereinfacht die durchzuführenden Operationen deutlich. 
Wie im vorherigen Abschnitt schon erwähnt, haben wir das Verfahren leicht umgeändert: damit wir die Zweierpotenzen nicht speichern müssen, iterieren wir nun vom höchsten Bit ausgehend bis zum ersten. Dabei entspricht jede $1$ an der Bitstelle $i$ einer Quadrierung und Multiplikation direkt danach und jede $0$ lediglich einer Quadrierung. Das höchstgesetze Bit wir dabei übersprungen, da wir mit $x^0$ anfangen und die $1^2 = 1$ ist. Stattdessen wird $x^1$ geschrieben, die Iteration beginnt also erst beim vorletzten Bit.
Um zu zeigen, dass das angepasste Verfahren das gleiche Ergebnis liefert, nehmen wir als Beispiel $n = 37$. Die Binärdarstellung von $37$ entspricht $100101$. Dann kann man $x^{37}$ als $Q Q QM Q QM$ darstellen wie oben beschrieben. Es gilt:
\begin{equation}
    x^{37} = (((((((x)^2)^2)^2) \cdot x)^2)^2) \cdot x
\end{equation}
Man braucht somit weniger Speicherplatz, weil hier nur die Matrix, wo das bisher erreichtes Ergebnis gespeichert wird, und die Anfangsmatrix $x^1$ für die Multiplikation gebraucht werden.
Für die Exponentiation reichen nur zwei bigNum-Funktionen aus, nämlich Addition und Multiplikation, wobei diese in den zwei nächsten Abschnitten ausführlich erklärt werden.
\subsection{Die Struktur, die uns erlaubt, die Zahlen mit beliebiger Genauigkeit zu speichern}%
Da unser Hauptinteresse darin besteht, die Konstante mit hoher Genauigkeit zu berechnen, müssen wir die Werte von $x_n$ und $x_{n+1}$ bei großem n berechnen, was bedeutet, dass diese Zahlen möglicherweise nicht in das \textit{long} Format des Computerprotokolls passen. Um dies zu tun, speichern wir sie als ein Array von vorzeichenlosen 32-Bit-Zahlen, die jeweils 32 Bits der binären Darstellung der Zahl enthalten. Um weitere Berechnungen bequemer durchzuführen, speichern wir unsere Zahl in einem Array von links nach rechts, d.h. das Null-Element des Arrays enthält die niedrigsten 32 Bits.\\
Wir wollen zum Beispiel die Zahl \textit{18446744073709558563} in unserer Struktur behalten. Die Darstellung im Binärsystem sieht wie folgt aus: \\
\centerline{\textit{1|000000000000000000000000000000|0000000000000000000001101100100011}}
Dann wird die in unserer Struktur wie folgt gespeichert:
\begin{equation*}
\begin{array}{|c|c|c|}\hline
array[0] & array[1] & array[2]\\
\hline
00000000000000000001101100100011 & 00000000000000000000000000000000 & 1\\ 
\hline
\end{array}
\end{equation*}
\subsection{Addition, Subtraktion und Multiplikation dieser Zahlen}%
\subsubsection{Addition und Subtraktion}%
Das Addieren und das Subtrahieren werden auf eine ähnliche Weise durchgeführt, wie wir es in der Schule gelernt haben. Man muss Zellen nacheinander addieren oder subtrahieren und dabei noch auf die Übertragung (Carry) achten, die das höhere Element beeinflüssen könnte.
\subsubsection{Multiplikation und Karatsuba-Algorithmus}%
Wie bereits erwähnt, liegt der Schwerpunkt der Arbeit auf dem Umgang mit großen Zahlen, deren naive Multiplikation sehr aufwendig sein kann und nur in $O(n^2)$ durchgeführt wird. Daher wurde beschlossen, diese Zahlen mit dem Karatsuba-Algorithmus   \cite{Karatsuba} zu multiplizieren, der es erlaubt, die gleichen Zahlen mit  je $n$ Bits in $O(n^{\log_23})$ zu multiplizieren. \\
Die Grundidee dieses Algorithmus, der einen Zeitgewinn darstellt, besteht darin, die Anzahl der Multiplikationsoperationen auf großen Zahlen zu reduzieren. Dies wird erreicht, wenn man die einzelne Multiplikationsoperation durch Addition, Subtraktion und bereits bekannte Ergebnisse rekursiv ausdrückt. \\
Genauer gesagt, repräsentieren wir unsere Faktoren $A$ und $B$ in dieser Form:
\begin{equation*}
A = ax + b \qquad B = cx + d 
\end{equation*} 
Und dann vereinfachen wir das Ergebnis der Multiplikation:
\begin{equation}\label{eq:karatsuba}
AB = ac\cdot x^2 + ((a + b)\cdot(c + d) - ac - bd)\cdot x + bd
\end{equation}
In dieser Form sieht man genauer, dass man die Kosten einer Multiplikation beibehalten hat.\\
In unserer Implementierung wiederholen wir ein ähnliches rekursives Aufteilungsverfahren, bis wir Zahlen haben, die durch ein einzelnes Element des obigen Arrays darstellbar sind und daher leicht multipliziert werden können.
\subsection{Division und das Divisionsergebnis}%
Der letzte Schritt bei der Berechnung der Konstante in unserem Algorithmus bestand darin, die beiden Integer-Zahlen zu dividieren und das Ergebnis im Real-Format darzustellen. Da wir nur ein enges Problem zu lösen hatten, entschieden wir uns, unsere reelle Zahl als Ganzzahl zu speichern und dabei zu berücksichtigen, dass die Ziffern dieser Zahl eigentlich die Nachkommastellen unserer Konstante darstellen. Dabei muss vorher $x_n$ entsprechend mit $10^n$ multipliziert werden bevor die eigentliche Division stattfindet. Die Division selbst funktioniert in unserem Fall nach dem Annäherungsprinzip: zuerst wird überprüft wie groß die Bitdifferenz $diff$ zwischen Dividenden und Teiler ist und danach werden alle Zweierpotenzen, anfangend von $2^{diff}$ ausprobiert und das Produkt $x_{n+1} \cdot 2^i$ von $x_n$ subtrahiert. Das Vorgehen wird solange wiederholt bis man alle Zweierpotenzen durchiteriert hat oder $x^n$ zufälligerweise $0$ geworden ist.\\
Es ist klar, dass selbst wenn unsere iterativen Terme als Fließkommazahlen nach IEEE-754 dargestellt werden könnten, das Ergebnis dieser Aufteilung für uns nicht funktionieren würde.  Bei unseren iterativen Termen handelt es sich um relativ große Zahlen und die Präzision ist für uns von größter Bedeutung. In IEEE-754 nimmt die Präzision, mit der die Zahl gespeichert wird, mit steigender Zahl ab. 

\subsection{Ausgabe in dezimaler und hexadezimaler Form }%
Es sei auch kurz darauf hingewiesen, dass die Übersetzung großer Zahlen in verschiedene Systeme mit den üblichen Methoden schwierig sein kann. Und so wurden zusätzliche Methoden auf Basis des Gorner-Schemas \cite{Gorner} geschaffen, um diese zu implementieren.
\section{Genauigkeit}
Wie in der Einleitung oben erwähnt, gehen wir davon aus, dass der Benutzer über die Konsole eingeben kann, mit welcher Genauigkeit das Ergebnis ausgegeben werden sollte. Wir haben uns dafür entschieden, dass in unserem Fall die Anzahl der korrekten Nachkommastellen eine angemessene Genauigkeit ist. Daher werden wir im Folgenden die Argumentation für die Schätzung der Anzahl der Iterationen demonstrieren, die erforderlich sind, um eine bestimmte Genauigkeit zu erreichen.\\ 
Zuerst kann gezeigt werden \cite{Primzahlen}, dass der n-te Term unserer Rekursion wie folgt aussieht:
\begin{equation}\label{eq:nthNum}
\frac{1}{2\sqrt{2}}((1+\sqrt{2})^n-(1-\sqrt{2})^n)
\end{equation}
Dann kann unsere Approximation an die Wurzel im n-ten Schritt wie folgt umgeschrieben werden:
\begin{equation}\label{eq:nthNumSqrt}
1+\frac{((1+\sqrt{2})^n-(1-\sqrt{2})^n)}{((1+\sqrt{2})^{n+1})-(1-\sqrt{2})^{n+1})}
\end{equation}
Und wir wollen ein geeignetes minimales $\emph{n}$ finden, damit der Betrag der Differenz aus unserer Konstante und der Approximation (\ref{eq:nthNumSqrt}) ein vorgegebenes $\varepsilon$ nicht überschreitet. Das heißt Folgendes ist erfüllt:
\begin{equation}\label{eq:errAprx}
|\sqrt{2}-1-\frac{((1+\sqrt{2})^n-(1-\sqrt{2})^n)}{((1+\sqrt{2})^{n+1})-(1-\sqrt{2})^{n+1})}|<\varepsilon
\end{equation}
Nach der Umwandlung sollte Folgendes gelten:
\begin{equation*}\label{eq:error2} 
\begin{cases} 
(\sqrt{2}-1)^n\cdot(4-2a+\varepsilon\cdot(a-1)<\varepsilon\cdot(1+\sqrt{2})^{n+1}
\\ (1-\sqrt{2})^n\cdot(4-2a-\varepsilon\cdot(a-1)<\varepsilon\cdot(1+\sqrt{2})^{n+1}
\end{cases}
\end{equation*}
Für ein gerades n ist erfüllt:
\begin{equation}\label{eq:errorLog} 
\begin{cases} 
n>\frac{log_2{(4-2\sqrt{2}-\varepsilon\cdot(\sqrt{2}-1))}-log_2{(1+\sqrt{2})}-log_2{\varepsilon}}{\log_2{(1+\sqrt{2})-\log_2{(\sqrt{2}-1)}}}
\\ n>\frac{log_2{(4-2\sqrt{2}+\varepsilon\cdot(\sqrt{2}-1))}-log_2{(1+\sqrt{2})}-log_2{\varepsilon}}{\log_2{(1+\sqrt{2})-\log_2{(\sqrt{2}-1)}}}
\end{cases}
\end{equation}
Der Nenner kann umgerechnet werden:
\begin{equation}\label{eq:denominator} 
\log_2{(1+\sqrt{2})}-\log_2{(\sqrt{2}-1)}=\log_2{(1+\sqrt{2})^2}=2\cdot\log_2{(1+\sqrt{2})}
\end{equation}
Nach \(\log_2{x}\leq x\) gilt es immer:
\begin{equation*}\label{eq:logx} 
log_2{(4-2\sqrt{2}+\varepsilon\cdot(\sqrt{2}-1))} - log_2{(4-2\sqrt{2})}<\varepsilon\cdot\frac{\sqrt{2}-1}{4-2\sqrt{2}}
\end{equation*}
D.h. es gilt für \(\varepsilon<1\):
\begin{equation}\label{eq:firstNum} 
log_2{(4-2\sqrt{2}+\varepsilon\cdot(\sqrt{2}-1))} < log_2{(4-2\sqrt{2})}+1
\end{equation}
Ähnlich für den zweiten Term:
\begin{equation}\label{eq:secondNum} 
log_2{(4-2\sqrt{2}-\varepsilon\cdot(\sqrt{2}-1))} < log_2{(4-2\sqrt{2})}+1
\end{equation}
Entsprechend erhalten wir aus (\ref{eq:denominator}), (\ref{eq:firstNum}), (\ref{eq:secondNum}) für den gesamten Ausdruck (\ref{eq:errorLog}):
\begin{equation}\label{eq:errorAprx} 
n>\frac{log_2{(4-2\sqrt{2})}-\log_2{\varepsilon}}{2\cdot\log_2{(1+\sqrt{2})}}
\end{equation}
Diese Formel (\ref{eq:errorAprx}) kann durch Schätzungen weiter vereinfacht werden:
\begin{equation*}\label{eq:errorAprxEasy} 
n>1+\frac{1}{2\cdot\log_2{\frac{1}{\varepsilon}}}
\end{equation*}
Und für unsere Bequemlichkeit:
\begin{equation*}
n>1+\frac{1}{2}\cdot\log_2{10}\cdot\log_{10}{\frac{1}{\varepsilon}}
\end{equation*}
\begin{equation*}
\log_2{10}\approx3.3
\end{equation*}
\begin{equation}\label{eq:finalAproximation}
n = \lceil 1+1.65\cdot\log_{10}{\frac{1}{\varepsilon}}\rceil
\end{equation}
Das Schöne an dieser Formel (\ref{eq:finalAproximation}) ist, dass wir den Logarithmus nicht berechnen müssen, weil wir stattdessen gleich die Anzahl der Nachkommastellen einsetzen können.\\
Außerdem ist leicht zu erkennen, dass diese Formel (\ref{eq:finalAproximation}) unter Verwendung der Eigenschaften des Logarithmus auf das Hexadezimalsystem übertragen werden kann.




\section{Performanzanalyse}
In diesem Abschnitt analysieren wir die Performanz durch die Zeitmessungen der einzelnen Methoden unter verschiedenen Eingaben. Alle Zeitmessungen, die im Folgenden dargestellt werden, wurden auf dem lokalen, immer gleichen PC $5$ mal ausgeführt, der mittlere Wert daraus berechnet und in die Tabelle eingetragen. Die Ergebnisse wurden in Sekunden gemessen:
\begin{center}
    \begin{tabular}{|c|c|c|c|c|c|c}
    \hline
 n & 1 & 10 & 100 & 1000 & 10000 \\
\hline
SimpleExponentiation & 0.000068 & 0.000090 & 0.003510 & 0.575478 & >2 min \\
\hline
BinaryExponentiation & 0.000071  & 0.000070  & 0.000277 & 0.004216 & 0.171003 \\ 
\hline
    \end{tabular}
\end{center}
Der Grund für die entsprechende Zeitmessung bei der Eingabe n = 10000 mit der matrixSimpleExponentiation ist, dass wir Karazuba-Multiplikation angewendet haben und diese nur dann sehr effizient funktioniert, wenn die Zahlen ungefähr gleich groß sind. Bei der normalen Exponentiation wird immer die Ausgangsmatrix mit der aktuellen Matrix multipliziert, was natürlich sehr ineffektiv ist, da die aktuelle Matrix sehr schnell wächst und die Ausgangsmatrix immer gleich bleibt.
Bevor wir unsere erreichte Ergebnisse und deren Bedeutung zusammenfassen wollen wir noch die Zeitmessungen der Division zweier großen Zahlen analysieren. Genauso wie vorher sind alle Ergebnisse in Sekunden gemessen worden:
\begin{center}
    \begin{tabular}{|c|c|c|c|c|c|}
    \hline
 n = 1 & n = 10 & n = 25 & n = 50 & n = 100 & n = 250 \\
\hline
0.000058 & 0.000093 & 0.000318 & 0.001426 & 0.006952 & 0.094541  \\
  \hline
  &&&&&\\
\hline
 n = 400 & n = 500 & n = 750 & n = 1000 & n = 2000 & n = 3000 \\
\hline
0.409463 & 0.827066 & 2.311850 & 6.335765 & 57.536390 & 207.34 \\
\hline
 \end{tabular}
 \end{center}

Es ist offensichtlich, dass der Algorithmus nicht in $O(n)$ liegt. Man sieht, dass die gemessene Zeit bei steigenden Eingaben bis $n = 500$ relativ langsam wächst. Der Grund dafür ist die Tatsache, dass $x_n$ zuerst mit $10^n$ multipliziert wird und das macht natürlich die Division umso zeitaufwendiger, je größer die Bitdifferenz vom Teiler und Dividenden sind, was bei großen Nutzereingaben der Fall ist. 

\section{Zusammenfassung und Ausblick}
Es ist offensichtlich, dass unsere Implementierung auf jeden Fall noch weiter zu optimieren ist. Beispielsweise der Algorithmus für die Division, den wir ausgesucht haben ist bei weitem nicht der schnellste. Da unser Projekt sich hauptsächlich mit der schnellen Exponentiation befasst, haben wir uns entschieden den Fokus auf andere Optimierungen zu legen. Trotzdem sind die von uns optimierten Methoden bemerkbar schneller und manche Ergebnisse überraschend schnell, obwohl bei einer relativ großer Eingabe enorm viele Bitoperationen stattfinden.

% TODO: Fuegen Sie Ihre Quellen der Datei Ausarbeitung.bib hinzu
% Referenzieren Sie diese dann mit \cite{}.
% Beispiel: CR2 ist ein Register der x86-Architektur~\cite{intel2017man}.
\bibliographystyle{plain}
\bibliography{Ausarbeitung}{}

\end{document}